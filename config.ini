[PATHS]
path_to_MLOIS: /home/zvladimi/MLOIS/
path_to_pickle: /home/zvladimi/MLOIS/pickle_data/
path_to_calc_info: /home/zvladimi/MLOIS/calculated_info/
path_to_xgboost: /home/zvladimi/MLOIS/xgboost_results/
path_to_pygadgetreader: /home/zvladimi/MLOIS/.pygadgetreader/
path_to_sparta: /home/zvladimi/MLOIS/.sparta_dev/analysis/
path_to_snaps: /home/zvladimi/MLOIS/SPARTA/sparta_data/snaps/
path_to_SPARTA_data: /home/zvladimi/MLOIS/SPARTA/sparta_output/

[MISC]
curr_sparta_file:cbol_l0063_n0256_4r200m_1-5v200m
# how are the snapshots formatted with regards to their number of 0s 
snap_dir_format={:04d}
snap_format={:04d}
random_seed=11
on_zaratan=False
use_gpu=False
# Options anything default in colossus or planck13-nbody
sim_cosmol=bolshoi

[SEARCH]
# RESET LEVELS for calc_ptl_props.py (no impact on train_xgboost.py)
# 0: no reset will just run from the beginning or continue from where the last run left off
# 1: Removes the calculated information (ptl_info and halo_info) and redoes all the calculations
# 2: Same as 1 and removes the the particle trees and the number of particles per halo
# 3: Same as 2 and removes all pickled data about the halos and particles from SPARTA/the simulation
reset = 1

# Only want one snapshot?
prim_only=False
# How many dynamical times should the snapshots be separated
t_dyn_step=2
# Will find the closest redshift to what is inputted so no need for an exact number
p_red_shift=-0.07
# In R200m search for particles around halo centers. Ideally will match what SPARTA's profiles go out to
search_rad=4
total_num_snaps=193
# How many things are being saved about the particles
# If for calc_ptl_props 7: halo_first, halo_n, HPIDS, Orbit/Infall, Radius, Rad Vel, Tang Vel, 
# If for morb_cat 6: Halo_ID, Halo_pos, Halo_vel, M_orb, M200m, R200m
num_save_ptl_params=7
# save size for each pd dataframe that is saved to HDF5 File
# The corresponding HDF5 will likely be a bit bigger depending on the size of the PD df
hdf5_mem_size = 2.5e9
# Chunksize for multiprocessing
chunk_size=250

[XGBOOST]
# RETRAIN LEVELS for train_xgboost.py
# 0: no retraining will just predict with current model (if there is one otherwise will train a new one) on test dataset
# 1: will retrain model but use old parameters (if they exist)
# 2: will retrain model with new parameters
retrain = 2
feature_columns = ["p_Scaled_radii","p_Radial_vel","p_Tangential_vel","c_Scaled_radii","c_Radial_vel","c_Tangential_vel"]
target_column = ["Orbit_infall"]

# The maximum number of particle files to be loaded per simulation. Used to roughly balance the amount of data used in the model
# from each simulation. calc_ptl_props should have used the same hdf5_mem_size param for each sim. To not use this simply enter 0
file_lim = 1

# Should be full name of the simulation calculated info folder
# THE ORDER OF SIMULATIONS MATTERS FOR REFERENCING HALOS
# determines what model is trained in train_xgboost.py and what model performs the preds in test_xgboost.py
model_sims:["cbol_l0063_n1024_4r200m_1-5v200m_100to90","cbol_l0125_n1024_4r200m_1-5v200m_100to90","cbol_l0250_n1024_4r200m_1-5v200m_100to90","cbol_l0500_n1024_4r200m_1-5v200m_100to90","cbol_l1000_n1024_4r200m_1-5v200m_100to90","cbol_l2000_n1024_4r200m_1-5v200m_100to90"] 
test_halos_ratio=0.25
# only used in test_xgboost.py. Should be a list of lists, each sublist is the sims used for a singular model.
# [[l0063_n1024,l1000_n1024]] is one model using 2 sims while [[l0063_n1024],[l1000_n1024]] is two models each using 1 sim
test_sims:[["cbol_l0063_n0256_4r200m_1-5v200m_190to166"]] 
# Name is important as that is how separate models for the same dataset can be referenced
model_type:base_flim1
#TODO implement "Full" dataset so it actually works
# Options are "Full", "Train", "Test". Can be any combination of the three
# This is used in reference to model_sims' dataset in train_xgboost.py and test_sims' dataset in test_xgboost.py
eval_datasets:["Test"]

# TRAIN DATASET ADJUSTMENT PARAMS
# for each adjustment set any (or all) of the params to 0 for these adjustments to not be performed

# The following two parameters adjust the number of particles used in the training. This is done by dividing the radii into log bins, setting a maximum particle
# number based off the total number of particles within a radii and then limiting every following bin to that maximum number of particles.

# reduce_rad takes any radius (>0) and will set the amount of particles within that radii as the maximum number of particles per following radius bin
# reduce_perc takes a decimal and will scale the maximum amount 
reduce_rad = 0
reduce_perc = 0.001

# You can also determine a radius after which orbiting particles will start to be weighted less on an exponential curve (less important the further out)
# weighting is of form: weights = e^((ln(min_weight)/(max_rad-weight_rad)) * (rad - weight_rad))
# weight_rad determines the radius at which this weighting starts (all particles with smaller radii have weights of 1)
# min_weight determines the lowest weight at the furthest radius. 
weight_rad = 0
min_weight = 0.01
weight_exp = 10

# Perform hyperparameter tuning on the weighting of the dataset. Overwrites the weight_rad/min_weight parameter
opt_wghts = False
opt_scale_rad = False

nu_splits=0-10
plt_nu_splits=0.5-1,1-1.5,1.5-2,2-3,3-6

# Mark as TRUE even if the hpo model has already been trained
hpo=False
# Options are:
# all: accuracy on all particles
# orb: accuracy on only orbiting particles
# inf: accuracy on only infalling particles (not recommended all does basically the same)
# mprf_all: accuracy on infalling + orbiting mass profiles
# mprf_orb: accuracy on only orbiting mass profile
hpo_loss = "all"
# the radius that the training dataset will be created up to
# the testing dataset will use all data
training_rad=5
rad_splits=0 # not currently implemented
frac_train_data=1

#TODO make it so that True/False is 1/0
#TODO add separate plots for density profile with nu splits and without
# What plots to make
dens_prf_plt     = True 
fulldist_plt     = True
misclass_plt     = True
io_frac_plt      = False
per_err_plt      = False

# For the missclass and fulldist plots where both linear and log scales are used can set
# the threshold for linear (from -thrsh to thrsh) and then the number of linear bins and log bins

linthrsh = 3
lin_nbin = 30
# THIS SHOULD BE DIVISIBLE BY 2 IF THERE ARE NEG and POS LOG BINS
log_nbin = 20 

# List the ticks that will be displayed. The location for imshow plots is automatically calculated.  
# rv ticks are mirrored for negative values
# Leave blank if not using
lin_rvticks = [0,0.5,1,2,3]
log_rvticks = [5,7.5,12]
lin_tvticks = [0,0.5,1,2,3]
log_tvticks = [5,7.5,12]
lin_rticks = [0,0.5,1,2,3,4]
log_rticks = []