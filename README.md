# ML_orbit_infall_project

This is a project with Dr. Benedikt Diemer that will use data from the nbody simulations run by Dr. Diemer and then processed with SPARTA [1][2][3]. The goal is to construct and compare several machine learning models in order to develop one that can accurately predict if a particle is either currently orbiting a dark matter halo or is infalling into one. This will be used to help better define the radius of a dark matter halo.

## Current State as of 06/30/2023
### Training Set Creation
In find_particle_properties_ML.py data is loaded in from a SPARTA .hdf5 file and the radial velocity, tangential velocity, and radius of the particles are calculated from the particles' position and velocity and their corresponding halo's position and velocity and then labeled with whether they are orbiting or infalling. 

A "tree" is constructed using all of the particle's positions within the simulation's box. Each halo's position is then searched within an adjustable radius to get all the particles within that radius of the halo. These particles are then checked to see which halo they belong to and whether they are orbiting this specific halo (as discussed in the prior paragraph). The radii of each particle is then calculated making sure to account for periodic boundary conditions. Then the radial and tangential velocities of the particles are then calculated. The radii are scaled by R200m of the halo and the velocities by V200m of the halo and then returned tobe saved in a new hdf5 file which then serves as the training dataset. The search is broken up into steps by halo mass as the arrays from doing all the calculations at once consume too much memory (if you decide to run this code as is you might run into issues if you have less than 16GB of available RAM). This process is only currently done for one snapshot but it would be relatively easy to repeat the process for multiple snapshots by changing the curr_snapshot variable's value for each snapshot and that functionality will likely be explicitly coded in the not too distant future.

loading_functions.py contains the necessary code to load the properties of the particles and halos from either the SPARTA .hdf5 file or from the particle information files. To read the particle files pygadgetreader is used [4] to load in those properties. Current functionality allows for easy switching between .hdf5 files as new directories are created and pickle files are stored there. This cuts down on data loading time which is very useful due to the large amount of data being worked with. Future work can be done so more pickle files (for radius or radial velocity) can be created to skip those steps as well. 

calculation_functions.py contains various functions used during the search to calculate all the different pieces of information needed to calculate the radii and velocities as well as a few extra pieces of information that let you check the calculations.

visualization_functions.py contains functions that create graphs that are helpful for checking if the calculated values are correct. One function graphs the density profiles of the halos (the mass at set radial bins of all particles, only orbiting particles, and only infalling particles) for what SPARTA outputs and what is found by the search. This is still being worked on due to some issues with how particles are assigned to halos and whether they are orbiting or infalling a halo. It also contains functions to display a brute force approach of finding the particles around a halo to then compare with the tree search. Finally it contains a function that displays the scaled average radial velocity versus position which is useful for checking if the radial velocity is being calculated correctly.

### Machine Learning
There are currently two machine learning models implemented: XGBoost [5] and Scikit Learn's Random Forest [6]. These two models were chosen due to their relative ease of deployment and then getting results. However, these likely won't be a long term solution for a couple of reasons. First there does not seem to be an easy way to split the dataset and then iteratively train the model this is unfortunate as training these models on the full dataset is not feasible primarily due to memory constraints. In addition in the future multiple snapshots will be used and there are better models for analyzing time evolution in a system. I will continue to work on them and see if with tuning of parameters the accuracy can be increased.

The next step will likely to build some form of neural network architecture which will likely incorporate some form of recurrent neural network (RNN) to make use of analyzing time evolution of the particles across multiple snapshots.

## Citations
[1] Diemer, B. (2017). The splashback radius of halos from particle dynamics. i. the Sparta algorithm. The Astrophysical Journal Supplement Series, 231(1), 5. https://doi.org/10.3847/1538-4365/aa799c 
[2] Diemer, B. (2020). The splashback radius of halos from particle dynamics. III. halo catalogs, merger trees, and host–subhalo relations. The Astrophysical Journal Supplement Series, 251(2), 17. https://doi.org/10.3847/1538-4365/abbf51 
[3] Diemer, B. (2022). A dynamics-based density profile for dark haloes – I. Algorithm and basic results. Monthly Notices of the Royal Astronomical Society, 513(1), 573–594. https://doi.org/10.1093/mnras/stac878 
[4] Thompson R., 2014, pyGadgetReader: GADGET snapshot reader for python (ascl:1411.001)
[5] Chen, T., Guestrin, C. (2016). XGBoost. Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. https://doi.org/10.1145/2939672.2939785 
[6] Paper, D. (2019). Scikit-learn classifier tuning from simple training sets. Hands-on Scikit-Learn for Machine Learning Applications, 137–163. https://doi.org/10.1007/978-1-4842-5373-1_5 